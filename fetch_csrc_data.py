#!/usr/bin/env python3
"""
ä»èµ„æœ¬å¸‚åœºç”µå­åŒ–ä¿¡æ¯æŠ«éœ²å¹³å°è·å–æ–°å‘è¡ŒåŸºé‡‘æ•°æ®
ä½¿ç”¨ urllib å’Œæµè§ˆå™¨è‡ªåŠ¨åŒ–ä¸¤ç§æ–¹å¼
"""

import os
import json
import time
import urllib.request
import urllib.parse
from datetime import datetime, timedelta
import sys
import csv
import argparse

# å°è¯•å¯¼å…¥ schedule åº“ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç®€å•çš„ sleep æ–¹å¼
try:
    import schedule
    SCHEDULE_AVAILABLE = True
except ImportError:
    SCHEDULE_AVAILABLE = False
    print("æç¤º: å®‰è£… schedule åº“å¯è·å¾—æ›´å¥½çš„å®šæ—¶ä»»åŠ¡ä½“éªŒ: pip install schedule")

# æµè§ˆå™¨è‡ªåŠ¨åŒ–æ¨¡å—
try:
    from browser_fetcher import fetch_csrc_data_browser
    BROWSER_AVAILABLE = True
except ImportError:
    BROWSER_AVAILABLE = False
    print("æµè§ˆå™¨è‡ªåŠ¨åŒ–æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä»…ä½¿ç”¨urllibæ–¹å¼")


def fetch_csrc_data():
    """ä» CSRC ç½‘ç«™è·å–åŸºé‡‘æ•°æ®"""

    # API åœ°å€å’Œå‚æ•°
    base_url = "http://eid.csrc.gov.cn/fund/disclose/advanced_search_report.do"

    current_date_str = datetime.now().strftime('%Y-%m-%d')
    yesterday_str = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')

    # è®¾ç½®è¯·æ±‚å‚æ•°
    ao_data = [
        {"name": "sEcho", "value": 2},
        {"name": "iColumns", "value": 6},
        {"name": "sColumns", "value": ",,,,,,"},
        {"name": "iDisplayStart", "value": 0},
        {"name": "iDisplayLength", "value": 20},
        {"name": "mDataProp_0", "value": "fundCode"},
        {"name": "mDataProp_1", "value": "fundId"},
        {"name": "mDataProp_2", "value": "reportName"},
        {"name": "mDataProp_3", "value": "organName"},
        {"name": "mDataProp_4", "value": "reportDesp"},
        {"name": "mDataProp_5", "value": "reportSendDate"},
        {"name": "fundType", "value": "6020-6050"},
        {"name": "reportType", "value": "FA010010"},
        {"name": "reportYear", "value": ""},
        {"name": "fundCompanyShortName", "value": ""},
        {"name": "fundCode", "value": ""},
        {"name": "fundShortName", "value": ""},
        {"name": "startUploadDate", "value": yesterday_str},
        {"name": "endUploadDate", "value": current_date_str}
    ]

    # å°†å‚æ•°ç¼–ç ä¸º JSON å­—ç¬¦ä¸²
    ao_data_str = urllib.parse.quote(json.dumps(ao_data))
    timestamp_ms_str = str(int(time.time() * 1000))
    api_url = f"{base_url}?aoData={ao_data_str}&_={timestamp_ms_str}"

    try:
        print(f"æ­£åœ¨è·å–æ•°æ®ä»: {api_url}")

        # åˆ›å»ºè¯·æ±‚å¯¹è±¡
        req = urllib.request.Request(api_url)

        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
        req.add_header('User-Agent',
                       'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36')
        req.add_header('Accept', 'application/json, text/javascript, */*; q=0.01')
        req.add_header('Accept-Language', 'zh-CN,zh;q=0.9')
        req.add_header('Content-Type', 'application/json')
        req.add_header('Host', 'eid.csrc.gov.cn')
        req.add_header('Referer', 'http://eid.csrc.gov.cn/fund/disclose/fund_detail.do?fundId=15977&rnd=0.9272639559371317')
        req.add_header('X-Requested-With', 'XMLHttpRequest')

        # å‘é€è¯·æ±‚å¹¶è·å–å“åº”
        with urllib.request.urlopen(req, timeout=60) as response:
            # è·å–å“åº”çŠ¶æ€ç 
            status_code = response.getcode()
            print(f"HTTP çŠ¶æ€ç : {status_code}")

            # è¯»å–å“åº”å¤´ä¿¡æ¯
            content_type = response.headers.get('Content-Type', '')
            print(f"Content-Type: {content_type}")

            # è¯»å–å“åº”å†…å®¹
            content = response.read().decode('utf-8')
            print(f"å“åº”å†…å®¹é•¿åº¦: {len(content)}")

            # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œè¿”å› None
            if not content or len(content.strip()) == 0:
                print("å“åº”å†…å®¹ä¸ºç©º")
                return None

            # å°è¯•è§£æ JSON
            try:
                data = json.loads(content)
                print(f"æˆåŠŸè§£æ JSON æ•°æ®ï¼Œæ•°æ®ç±»å‹: {type(data)}")
                return data
            except json.JSONDecodeError as e:
                print(f"JSON è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹: {e}")
                # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
                return content

    except urllib.error.URLError as e:
        print(f"API è¯·æ±‚å¤±è´¥: {e}")
        if hasattr(e, 'reason'):
            print(f"å¤±è´¥åŸå› : {e.reason}")
        return None
    except urllib.error.HTTPError as e:
        print(f"HTTP é”™è¯¯: {e.code} - {e.reason}")
        return None
    except Exception as e:
        print(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {e}")
        return None


def process_fund_data(data):
    """å¤„ç†åŸºé‡‘æ•°æ®ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""

    if not data:
        return []

    # å¦‚æœæ•°æ®æ˜¯å­—ç¬¦ä¸²ï¼ˆHTML æˆ–å…¶ä»–æ ¼å¼ï¼‰ï¼Œå°è¯•æå–æœ‰ç”¨ä¿¡æ¯
    if isinstance(data, str):
        print("æ•°æ®æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå°è¯•å¤„ç†...")
        # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…è¿”å›æ ¼å¼è¿›è¡Œè§£æ
        # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨
        return []

    # å¦‚æœæ•°æ®æ˜¯å­—å…¸ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ aaData å­—æ®µï¼ˆå®é™…APIè¿”å›æ ¼å¼ï¼‰
    if isinstance(data, dict):
        if 'aaData' in data and isinstance(data['aaData'], list):
            print(f"ä» aaData ä¸­æå–æ•°æ®ï¼Œå…± {len(data['aaData'])} æ¡è®°å½•")
            return data['aaData']
        elif 'data' in data and isinstance(data['data'], list):
            return data['data']
        else:
            return [data]
    elif isinstance(data, list):
        return data
    else:
        print(f"ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {type(data)}")
        return []


def save_fund_data_to_csv(fund_data, filename='data/csrc_fund_data.csv'):
    """ä¿å­˜åŸºé‡‘æ•°æ®åˆ° CSV æ–‡ä»¶ï¼Œä»¥ uploadInfoDetailId ä¸ºä¸»é”®è¿›è¡Œå»é‡"""

    if not fund_data:
        print("æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
        return False

    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    os.makedirs('data', exist_ok=True)

    try:
        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆè¯»å–ç°æœ‰æ•°æ®å¹¶åˆ›å»ºä»¥ uploadInfoDetailId ä¸ºé”®çš„å­—å…¸
        existing_data_dict = {}
        if os.path.exists(filename):
            with open(filename, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # ä½¿ç”¨ uploadInfoDetailId ä½œä¸ºä¸»é”®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è·³è¿‡
                    if 'uploadInfoDetailId' in row:
                        existing_data_dict[row['uploadInfoDetailId']] = row

        # å‡†å¤‡æ–°æ•°æ®ï¼ŒåŒæ ·ä»¥ uploadInfoDetailId ä¸ºé”®
        new_data_dict = {}
        for item in fund_data:
            # ç¡®ä¿æœ‰ uploadInfoDetailId å­—æ®µ
            if 'uploadInfoDetailId' in item:
                # æ·»åŠ æ—¶é—´æˆ³
                item['fetched_at'] = current_time
                new_data_dict[str(item['uploadInfoDetailId'])] = item
            else:
                print(f"è­¦å‘Š: æ•°æ®é¡¹ç¼ºå°‘ uploadInfoDetailId å­—æ®µï¼Œå·²è·³è¿‡: {item}")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®
        existing_ids = set(existing_data_dict.keys())
        new_ids = set(new_data_dict.keys())

        # æ‰¾å‡ºçœŸæ­£çš„æ–°æ•°æ®ï¼ˆä¸åœ¨ç°æœ‰æ•°æ®ä¸­çš„ï¼‰
        truly_new_ids = new_ids - existing_ids

        if not truly_new_ids:
            print("æ²¡æœ‰æ–°çš„æ•°æ®éœ€è¦ä¿å­˜")
            return True

        print(f"å‘ç° {len(truly_new_ids)} æ¡æ–°æ•°æ®")

        # åªå¤„ç†æ–°æ•°æ®
        final_new_data = {id_: new_data_dict[id_] for id_ in truly_new_ids}

        # è·å–æ–°æ•°æ®ç”¨äºé‚®ä»¶é€šçŸ¥
        new_data_for_email = []
        for id_ in truly_new_ids:
            new_data_for_email.append(new_data_dict[id_])

        # åˆå¹¶æ•°æ®ï¼Œåªæ·»åŠ æ–°æ•°æ®
        merged_data_dict = existing_data_dict.copy()
        merged_data_dict.update(final_new_data)

        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰ uploadInfoDetailId æ’åº
        all_data = list(merged_data_dict.values())
        all_data.sort(key=lambda x: int(x['uploadInfoDetailId']))

        # è·å–æ‰€æœ‰å¯èƒ½çš„å­—æ®µ
        all_fields = set()
        for item in all_data:
            all_fields.update(item.keys())

        # å®šä¹‰æ ¸å¿ƒå­—æ®µçš„é¡ºåºï¼Œå…¶ä»–å­—æ®µæŒ‰å­—æ¯é¡ºåºæ’åˆ—
        core_fields = ['uploadInfoDetailId', 'fundCode', 'fundShortName', 'reportName',
                      'organName', 'reportDesp', 'uploadDate', 'reportSendDate', 'fetched_at']
        other_fields = sorted([f for f in all_fields if f not in core_fields])
        all_fields = core_fields + other_fields

        # å†™å…¥ CSV æ–‡ä»¶
        with open(filename, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=all_fields)
            writer.writeheader()
            writer.writerows(all_data)

        new_records_count = len(final_new_data)
        total_records_count = len(all_data)
        print(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        print(f"æ–°å¢è®°å½•: {new_records_count} æ¡")
        print(f"æ€»è®°å½•æ•°: {total_records_count} æ¡")

        # å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆå¦‚æœæœ‰æ–°æ•°æ®ä¸”é…ç½®äº†é‚®ä»¶åŠŸèƒ½ï¼‰
        if new_data_for_email:
            try:
                from email_notifier import SimpleEmailNotifier

                # åˆ›å»ºé‚®ä»¶é€šçŸ¥å™¨
                email_notifier = SimpleEmailNotifier()

                # æ£€æŸ¥æ˜¯å¦é…ç½®äº†é‚®ä»¶åŠŸèƒ½
                if email_notifier.is_configured():
                    print("æ­£åœ¨å‘é€é‚®ä»¶é€šçŸ¥...")

                    # å‘é€é‚®ä»¶é€šçŸ¥
                    success = email_notifier.send_fund_notification(new_data_for_email)

                    if success:
                        print("âœ… é‚®ä»¶é€šçŸ¥å‘é€æˆåŠŸ")
                    else:
                        print("âŒ é‚®ä»¶é€šçŸ¥å‘é€å¤±è´¥")
                else:
                    print("é‚®ä»¶åŠŸèƒ½æœªé…ç½®ï¼ˆå¦‚éœ€ä½¿ç”¨ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼šEMAIL_ADDRESS, EMAIL_PASSWORDï¼‰")

            except ImportError:
                print("é‚®ä»¶æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè·³è¿‡é‚®ä»¶é€šçŸ¥")
            except Exception as e:
                print(f"é‚®ä»¶é€šçŸ¥å‘é€å¼‚å¸¸: {e}")
                # é‚®ä»¶å‘é€å¤±è´¥ä¸å½±å“ä¸»ç¨‹åºç»§ç»­è¿è¡Œ

        return True

    except Exception as e:
        print(f"ä¿å­˜ CSV æ–‡ä»¶å¤±è´¥: {e}")
        return False


def fetch_and_save_data():
    """æ‰§è¡Œä¸€æ¬¡æ•°æ®è·å–å’Œä¿å­˜çš„å®Œæ•´æµç¨‹"""
    print(f"\n{'='*60}")
    print(f"å¼€å§‹è·å– CSRC åŸºé‡‘æ•°æ®... {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ•°æ®æ¥æº: èµ„æœ¬å¸‚åœºç”µå­åŒ–ä¿¡æ¯æŠ«éœ²å¹³å°")
    print(f"{'='*60}\n")

    raw_data = None

    # é¦–å…ˆå°è¯•ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–æ–¹å¼
    if BROWSER_AVAILABLE and os.environ.get('USE_BROWSER_FETCHER', 'false').lower() == 'true':
        print("å°è¯•ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–æ•°æ®...")
        try:
            raw_data = fetch_csrc_data_browser()
            if raw_data:
                print(f"æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–æˆåŠŸï¼Œå…± {len(raw_data)} æ¡æ•°æ®")
            else:
                print("æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–å¤±è´¥ï¼Œå°†å°è¯•urllibæ–¹å¼")
        except Exception as e:
            print(f"æµè§ˆå™¨è‡ªåŠ¨åŒ–å‡ºé”™: {e}")
            print("å°†å°è¯•urllibæ–¹å¼")

    # å¦‚æœæµè§ˆå™¨æ–¹å¼å¤±è´¥ï¼Œå°è¯•urllibæ–¹å¼
    if raw_data is None:
        print("ä½¿ç”¨urllibæ–¹å¼è·å–æ•°æ®...")
        raw_data = fetch_csrc_data()

    if raw_data is None:
        print("âŒ è·å–æ•°æ®å¤±è´¥")
        return False

    # å¤„ç†æ•°æ®
    fund_data = process_fund_data(raw_data)
    print(f"å¤„ç†åçš„æ•°æ®é‡: {len(fund_data)}")

    if fund_data:
        print("æ•°æ®ç¤ºä¾‹:")
        for i, item in enumerate(fund_data[:3]):  # æ˜¾ç¤ºå‰3æ¡æ•°æ®
            print(f"  {i + 1}: {item}")

    # ä¿å­˜åˆ° CSV æ–‡ä»¶
    success = save_fund_data_to_csv(fund_data)

    if success:
        print("âœ… æ•°æ®ä¿å­˜æˆåŠŸ!")
    else:
        print("âŒ æ•°æ®ä¿å­˜å¤±è´¥!")
        return False

    print(f"\n{'='*60}")
    print(f"ä»»åŠ¡å®Œæˆ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")
    return True


def run_with_schedule(interval_minutes=30):
    """ä½¿ç”¨ schedule åº“è¿è¡Œå®šæ—¶ä»»åŠ¡"""
    print(f"ğŸ“… ä½¿ç”¨ schedule åº“å¯åŠ¨å®šæ—¶ä»»åŠ¡")
    print(f"â° æ‰§è¡Œé—´éš”: æ¯ {interval_minutes} åˆ†é’Ÿ")
    print(f"ğŸ”„ æŒ‰ Ctrl+C åœæ­¢ä»»åŠ¡\n")

    # ç«‹å³æ‰§è¡Œä¸€æ¬¡
    fetch_and_save_data()

    # è®¾ç½®å®šæ—¶ä»»åŠ¡
    schedule.every(interval_minutes).minutes.do(fetch_and_save_data)

    # æŒç»­è¿è¡Œ
    try:
        while True:
            schedule.run_pending()
            time.sleep(1)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºå®šæ—¶ä»»åŠ¡")


def run_with_simple_loop(interval_minutes=30):
    """ä½¿ç”¨ç®€å•çš„å¾ªç¯å’Œ sleep è¿è¡Œå®šæ—¶ä»»åŠ¡"""
    print(f"ğŸ“… ä½¿ç”¨ç®€å•å¾ªç¯å¯åŠ¨å®šæ—¶ä»»åŠ¡")
    print(f"â° æ‰§è¡Œé—´éš”: æ¯ {interval_minutes} åˆ†é’Ÿ")
    print(f"ğŸ”„ æŒ‰ Ctrl+C åœæ­¢ä»»åŠ¡\n")

    try:
        while True:
            # æ‰§è¡Œä»»åŠ¡
            fetch_and_save_data()

            # ç­‰å¾…æŒ‡å®šæ—¶é—´
            interval_seconds = interval_minutes * 60
            print(f"â³ ç­‰å¾… {interval_minutes} åˆ†é’Ÿåæ‰§è¡Œä¸‹ä¸€æ¬¡ä»»åŠ¡...")
            print(f"   ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {(datetime.now() + timedelta(minutes=interval_minutes)).strftime('%Y-%m-%d %H:%M:%S')}")
            time.sleep(interval_seconds)

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºå®šæ—¶ä»»åŠ¡")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ä» CSRC è·å–æ–°å‘è¡ŒåŸºé‡‘æ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å•æ¬¡æ‰§è¡Œ
  python fetch_csrc_data.py

  # æ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼ˆé»˜è®¤ï¼‰
  python fetch_csrc_data.py --schedule

  # æ¯60åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
  python fetch_csrc_data.py --schedule --interval 60

  # æ¯10åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
  python fetch_csrc_data.py --schedule --interval 10
        """
    )

    parser.add_argument(
        '--schedule',
        action='store_true',
        help='å¯ç”¨å®šæ—¶ä»»åŠ¡æ¨¡å¼ï¼ˆæŒç»­è¿è¡Œï¼‰'
    )

    parser.add_argument(
        '--interval',
        type=int,
        default=30,
        help='å®šæ—¶ä»»åŠ¡æ‰§è¡Œé—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤30åˆ†é’Ÿ'
    )

    args = parser.parse_args()

    if args.schedule:
        # å®šæ—¶ä»»åŠ¡æ¨¡å¼
        if args.interval <= 0:
            print("âŒ é”™è¯¯: é—´éš”æ—¶é—´å¿…é¡»å¤§äº0")
            sys.exit(1)

        # ä¼˜å…ˆä½¿ç”¨ schedule åº“ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ç®€å•å¾ªç¯
        if SCHEDULE_AVAILABLE:
            run_with_schedule(args.interval)
        else:
            run_with_simple_loop(args.interval)
    else:
        # å•æ¬¡æ‰§è¡Œæ¨¡å¼
        success = fetch_and_save_data()
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
